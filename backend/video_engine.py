import os
import requests
import random
import numpy as np

# [í•„ìˆ˜] Pillow í˜¸í™˜ì„± íŒ¨ì¹˜
import PIL.Image
if not hasattr(PIL.Image, 'ANTIALIAS'):
    PIL.Image.ANTIALIAS = PIL.Image.LANCZOS

from PIL import Image, ImageDraw, ImageFont
from moviepy.editor import VideoFileClip, AudioFileClip, ImageClip, CompositeVideoClip, concatenate_videoclips, vfx
from dotenv import load_dotenv

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
load_dotenv(os.path.join(BASE_DIR, ".env"))
PEXELS_API_KEY = os.getenv("PEXELS_API_KEY")

# 1. ì˜ìƒ ë‹¤ìš´ë¡œë“œ (í™”ì§ˆ ìµœì í™” ìœ ì§€)
def download_stock_video(query, duration, filename="temp_video.mp4"):
    headers = {"Authorization": PEXELS_API_KEY}
    
    search_queries = [query]
    fallback_keywords = ["technology", "business", "city", "future", "abstract", "nature"]
    search_queries.extend(fallback_keywords)

    for keyword in search_queries:
        print(f"ğŸ” Pexels ê²€ìƒ‰ ì‹œë„: '{keyword}'")
        url = f"https://api.pexels.com/videos/search?query={keyword}&orientation=portrait&per_page=20"
        
        try:
            response = requests.get(url, headers=headers)
            if response.status_code != 200: continue
            
            data = response.json()
            if "videos" in data and len(data["videos"]) > 0:
                best_video_link = None
                random.shuffle(data["videos"]) 
                
                for v in data["videos"]:
                    for f in v["video_files"]:
                        w = f["width"]
                        h = f["height"]
                        if 720 <= w <= 1920:
                            best_video_link = f["link"]
                            print(f"   ğŸ¯ ë”± ì¢‹ì€ í™”ì§ˆ ë°œê²¬! ({w}x{h})")
                            break 
                    if best_video_link: break
                
                if not best_video_link:
                      print("   âš ï¸ ë”± ë§ëŠ” í™”ì§ˆì´ ì—†ì–´ì„œ ì°¨ì„ ì±…ì„ ì°¾ìŠµë‹ˆë‹¤.")
                      for v in data["videos"]:
                        for f in v["video_files"]:
                            if f["width"] >= 720:
                                best_video_link = f["link"]
                                break
                        if best_video_link: break

                if not best_video_link:
                    print("   âŒ ì“¸ë§Œí•œ í™”ì§ˆì´ ì—†ì–´ì„œ ë„˜ì–´ê°‘ë‹ˆë‹¤.")
                    continue

                print(f"ğŸ¬ ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì‹œì‘... (ì£¼ì œ: {keyword})")
                with open(filename, 'wb') as f:
                    f.write(requests.get(best_video_link).content)
                print("âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
                return filename
                
        except Exception as e:
            print(f"âš ï¸ ì—ëŸ¬ ë°œìƒ: {e}")
            continue
            
    return None

# [ìˆ˜ì •ë¨] 2. ìë§‰ ì´ë¯¸ì§€ ìƒì„± (ê·¸ë¦¼ì ì œê±°, ê¹”ë”í•œ ì™¸ê³½ì„  ìŠ¤íƒ€ì¼)
def create_text_image(text, font_path, video_w, video_h):
    img = Image.new('RGBA', (video_w, video_h), (0, 0, 0, 0))
    draw = ImageDraw.Draw(img)
    
    # í°íŠ¸ í¬ê¸°: ì˜ìƒ ë„ˆë¹„ì˜ 7%
    fontsize = int(video_w * 0.07)
    
    try:
        font = ImageFont.truetype(font_path, fontsize) 
    except:
        font = ImageFont.load_default()
    
    max_width = video_w * 0.85
    
    # ì¤„ë°”ê¿ˆ ë¡œì§
    words = text.split(' ') 
    lines = []
    current_line_words = []
    
    for word in words:
        test_line = ' '.join(current_line_words + [word])
        bbox = draw.textbbox((0, 0), test_line, font=font)
        line_width = bbox[2] - bbox[0]
        
        if line_width <= max_width:
            current_line_words.append(word)
        else:
            if current_line_words:
                lines.append(' '.join(current_line_words))
            current_line_words = [word]
            
    if current_line_words:
        lines.append(' '.join(current_line_words))
        
    final_text = "\n".join(lines)
    
    # ì¤„ ê°„ê²© (ê¹”ë”í•˜ê²Œ ë–¨ì–´ì§€ë„ë¡ 15% ì •ë„)
    line_spacing = int(fontsize * 0.15)
    
    # ì „ì²´ í…ìŠ¤íŠ¸ ë°•ìŠ¤ í¬ê¸° ê³„ì‚°
    bbox = draw.multiline_textbbox((0, 0), final_text, font=font, align="center", spacing=line_spacing)
    text_w = bbox[2] - bbox[0]
    text_h = bbox[3] - bbox[1]
    
    x = (video_w - text_w) / 2
    bottom_margin = video_h * 0.2 
    y = video_h - text_h - bottom_margin 
    
    # [ìŠ¤íƒ€ì¼ í•µì‹¬] 
    # ê·¸ë¦¼ì(offsets ë£¨í”„) ë‹¤ ì—†ì• ê³ , ë”± 'stroke_width' í•˜ë‚˜ë§Œ ì‚¬ìš©í•´ì„œ ê¹”ë”í•˜ê²Œ ì²˜ë¦¬
    # ë‘ê»˜ëŠ” í°íŠ¸ í¬ê¸°ì˜ 4% (ë„ˆë¬´ ë‘ê»ì§€ ì•Šê²Œ)
    stroke_width = max(1, int(fontsize * 0.04))
    
    draw.multiline_text(
        (x, y), 
        final_text, 
        font=font, 
        fill=(255, 255, 0, 255),      # ê¸€ììƒ‰: ë…¸ë‘
        align="center", 
        spacing=line_spacing,
        stroke_width=stroke_width,    # í…Œë‘ë¦¬ ë‘ê»˜
        stroke_fill=(0, 0, 0, 255)    # í…Œë‘ë¦¬ ìƒ‰: ê²€ì •
    )
    
    return np.array(img)

# 3. í•©ì¹˜ê¸° (ë¬¼ë¦¬ì  ë°˜ë³µ + ë¦¬ì‚¬ì´ì§• ìœ ì§€)
def combine_clips(data_list, video_path, output_path):
    font_path = os.path.join(BASE_DIR, "fonts", "NanumGothic-Bold.ttf")
    if not os.path.exists(font_path): font_path = "arial.ttf"

    bg_video = VideoFileClip(video_path)

    # 1. 1080p -> 720p ë‹¤ì´ì–´íŠ¸
    if bg_video.h > 1280:
        print(f"ğŸ“‰ ê³ í™”ì§ˆ ê°ì§€! í•´ìƒë„ ì¶•ì†Œ ì¤‘... ({bg_video.h}p -> 1280p)")
        bg_video = bg_video.resize(height=1280)

    final_clips = []
    total_duration = 0
    
    for item in data_list:
        text = item['text']
        audio_file = item['audio']
        audio_clip = AudioFileClip(audio_file)
        duration = audio_clip.duration
        
        txt_img = create_text_image(text, font_path, bg_video.w, bg_video.h)
        txt_clip = ImageClip(txt_img).set_duration(duration).set_audio(audio_clip)
        
        final_clips.append(txt_clip)
        total_duration += duration

    content_clip = concatenate_videoclips(final_clips, method="compose")
    
    # 2. ë¬¼ë¦¬ì  ë°˜ë³µ (ì—ëŸ¬ ë°©ì§€)
    if bg_video.duration < total_duration:
        print(f"ğŸ”„ ì˜ìƒ ê¸¸ì´ ì—°ì¥ (ë¬¼ë¦¬ì  ë³µì‚¬)")
        n_loops = int(total_duration / bg_video.duration) + 2
        bg_video = concatenate_videoclips([bg_video] * n_loops)
    
    bg_video = bg_video.subclip(0, total_duration)
        
    w, h = bg_video.size
    target_ratio = 9/16
    if w/h > target_ratio:
        new_w = h * target_ratio
        bg_video = bg_video.crop(x1=w/2 - new_w/2, width=new_w, height=h)
    
    final_video = CompositeVideoClip([bg_video, content_clip])
    
    print("â³ ë Œë”ë§ ì‹œì‘ (ê¹”ë”í•œ ìŠ¤íƒ€ì¼)...")

    final_video.write_videofile(
        output_path, 
        codec="libx264", 
        audio_codec="aac", 
        fps=24, 
        preset='ultrafast',
        threads=4
    )

    final_video.close()
    bg_video.close()
    content_clip.close()
    
    return output_path