import os
import requests
import random
import numpy as np
from PIL import Image, ImageDraw, ImageFont
# ğŸ‘‡ [ìˆ˜ì •] vfx ì¶”ê°€ (ì˜ìƒ ë°˜ë³µ ë£¨í”„ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ í•„ìš”)
from moviepy.editor import VideoFileClip, AudioFileClip, ImageClip, CompositeVideoClip, concatenate_videoclips, vfx
from dotenv import load_dotenv

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
load_dotenv(os.path.join(BASE_DIR, ".env"))
PEXELS_API_KEY = os.getenv("PEXELS_API_KEY")

# 1. Pexels ì˜ìƒ ë‹¤ìš´ë¡œë“œ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
def download_stock_video(query, duration, filename="temp_video.mp4"):
    headers = {"Authorization": PEXELS_API_KEY}
    
    search_queries = [query]
    fallback_keywords = ["technology", "business", "city", "future", "abstract", "nature"]
    search_queries.extend(fallback_keywords)

    for keyword in search_queries:
        print(f"ğŸ” Pexels ê²€ìƒ‰ ì‹œë„: '{keyword}'")
        url = f"https://api.pexels.com/videos/search?query={keyword}&orientation=portrait&per_page=20"
        
        try:
            response = requests.get(url, headers=headers)
            if response.status_code != 200: continue
            
            data = response.json()
            if "videos" in data and len(data["videos"]) > 0:
                best_video_link = None
                random.shuffle(data["videos"]) 
                
                for v in data["videos"]:
                    for f in v["video_files"]:
                        w = f["width"]
                        h = f["height"]
                        # 720p ~ 1080p ì‚¬ì´ ì ì ˆí•œ í™”ì§ˆ ì°¾ê¸°
                        if 720 <= w <= 1920:
                            best_video_link = f["link"]
                            print(f"   ğŸ¯ ë”± ì¢‹ì€ í™”ì§ˆ ë°œê²¬! ({w}x{h})")
                            break 
                    if best_video_link: break
                
                if not best_video_link:
                      print("   âš ï¸ ë”± ë§ëŠ” í™”ì§ˆì´ ì—†ì–´ì„œ ì°¨ì„ ì±…ì„ ì°¾ìŠµë‹ˆë‹¤.")
                      for v in data["videos"]:
                        for f in v["video_files"]:
                            if f["width"] >= 720:
                                best_video_link = f["link"]
                                break
                        if best_video_link: break

                if not best_video_link:
                    print("   âŒ ì“¸ë§Œí•œ í™”ì§ˆì´ ì—†ì–´ì„œ ë„˜ì–´ê°‘ë‹ˆë‹¤.")
                    continue

                print(f"ğŸ¬ ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì‹œì‘... (ì£¼ì œ: {keyword})")
                with open(filename, 'wb') as f:
                    f.write(requests.get(best_video_link).content)
                print("âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
                return filename
                
        except Exception as e:
            print(f"âš ï¸ ì—ëŸ¬ ë°œìƒ: {e}")
            continue
            
    return None

# 2. ìë§‰ ì´ë¯¸ì§€ ìƒì„± (ê¸°ì¡´ ìœ ì§€)
def create_text_image(text, font_path, video_w, video_h):
    img = Image.new('RGBA', (video_w, video_h), (0, 0, 0, 0))
    draw = ImageDraw.Draw(img)
    
    # í°íŠ¸ í¬ê¸°: ë„ˆë¹„ì˜ 6%
    fontsize = int(video_w * 0.06)
    
    try:
        font = ImageFont.truetype(font_path, fontsize) 
    except:
        font = ImageFont.load_default()
    
    max_width = video_w * 0.85
    lines = []
    current_line = ""
    
    for char in text:
        bbox = draw.textbbox((0, 0), current_line + char, font=font)
        line_width = bbox[2] - bbox[0]
        
        if line_width <= max_width:
            current_line += char
        else:
            lines.append(current_line)
            current_line = char
    lines.append(current_line)
    
    final_text = "\n".join(lines)
    
    bbox = draw.textbbox((0, 0), final_text, font=font)
    text_w = bbox[2] - bbox[0]
    text_h = bbox[3] - bbox[1]
    
    x = (video_w - text_w) / 2
    bottom_margin = video_h * 0.15 
    y = video_h - text_h - bottom_margin 
    
    shadow_color = (0, 0, 0, 255)
    stroke_width = max(1, int(fontsize * 0.05))
    
    offsets = []
    for i in range(1, stroke_width + 1):
        offsets.extend([(i, i), (-i, -i), (i, -i), (-i, i), (i, 0), (-i, 0), (0, i), (0, -i)])
        
    for ox, oy in offsets:
        draw.text((x+ox, y+oy), final_text, font=font, fill=shadow_color, align="center")
    
    draw.text((x, y), final_text, font=font, fill=(255, 255, 0, 255), align="center")
    
    return np.array(img)

# 3. í•©ì¹˜ê¸° (ğŸš€ ìµœì í™” ì ìš©ë¨)
def combine_clips(data_list, video_path, output_path):
    font_path = os.path.join(BASE_DIR, "fonts", "NanumGothic-Bold.ttf")
    if not os.path.exists(font_path): font_path = "arial.ttf"

    bg_video = VideoFileClip(video_path)

    # [ğŸš¨ ìµœì í™” í•µì‹¬ 1] 1080p ì´ìƒì´ë©´ 720pë¡œ ê°•ì œ ë¦¬ì‚¬ì´ì§• (ì†ë„ 3ë°° í–¥ìƒ)
    if bg_video.h > 1280:
        print(f"ğŸ“‰ ê³ í™”ì§ˆ ê°ì§€! í•´ìƒë„ ì¶•ì†Œ ì¤‘... ({bg_video.h}p -> 1280p)")
        # ë†’ì´ë¥¼ 1280ìœ¼ë¡œ ë§ì¶”ë©´ ë„ˆë¹„ëŠ” ë¹„ìœ¨ì— ë§ì¶° ìë™ ì¡°ì ˆë¨
        bg_video = bg_video.resize(height=1280)

    final_clips = []
    total_duration = 0
    
    # í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„± (ë¦¬ì‚¬ì´ì§•ëœ í¬ê¸°ì— ë§ì¶°ì„œ ìƒì„±ë¨ -> ì—¬ê¸°ì„œë„ ì†ë„ ì´ë“)
    for item in data_list:
        text = item['text']
        audio_file = item['audio']
        audio_clip = AudioFileClip(audio_file)
        duration = audio_clip.duration
        
        txt_img = create_text_image(text, font_path, bg_video.w, bg_video.h)
        txt_clip = ImageClip(txt_img).set_duration(duration).set_audio(audio_clip)
        
        final_clips.append(txt_clip)
        total_duration += duration

    content_clip = concatenate_videoclips(final_clips, method="compose")
    
    # [ğŸš¨ ìµœì í™” í•µì‹¬ 2] vfx.loop ì‚¬ìš© (ë©”ëª¨ë¦¬ ì ˆì•½)
    if bg_video.duration < total_duration:
        print(f"ğŸ”„ ë°°ê²½ ì˜ìƒ ë£¨í”„ ì ìš© (ê¸¸ì´ ë§ì¶¤)")
        bg_video = vfx.loop(bg_video, duration=total_duration)
    else:
        bg_video = bg_video.subclip(0, total_duration)
        
    # 9:16 ë¹„ìœ¨ í¬ë¡­ (ì¤‘ì•™ ê¸°ì¤€)
    w, h = bg_video.size
    target_ratio = 9/16
    if w/h > target_ratio:
        new_w = h * target_ratio
        bg_video = bg_video.crop(x1=w/2 - new_w/2, width=new_w, height=h)
    
    final_video = CompositeVideoClip([bg_video, content_clip])
    
    print("â³ ë Œë”ë§ ì‹œì‘ (ì´ˆê³ ì† ëª¨ë“œ)...")

    # [ğŸš¨ ìµœì í™” í•µì‹¬ 3] ultrafast í”„ë¦¬ì…‹
    final_video.write_videofile(
        output_path, 
        codec="libx264", 
        audio_codec="aac", 
        fps=24, 
        preset='ultrafast',
        threads=4
    )

    final_video.close()
    bg_video.close()
    content_clip.close()
    
    return output_path